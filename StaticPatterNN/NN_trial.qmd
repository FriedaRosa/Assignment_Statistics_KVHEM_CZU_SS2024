---
title: "NeuralNetworks 1"
author: "Frieda"
format: html
editor: visual
---

```{r, message=FALSE}
# check package 
if(!require('torch',quietly = TRUE)) install.packages('torch')
library('torch') 

#install torch
if(!torch_is_installed()) install_torch()
```

```{r, message=FALSE}
install.packages("cito")
install.packages("plotly")
install.packages("igraph")
install.packages("ggraph")
library(ggraph)
library(igraph)
library(cito)
library(plotly)
library(dplyr)
```

```{r, message=FALSE}
library(cito)
nn.fit <- dnn(Sepal.Length~., data = datasets::iris, bootstrap = 30L)

analyze_training(nn.fit)
# At 1st glance, the networks converged since the loss is lower than the baseline loss and the training loss is on a plateau at the end of the training.#




set.seed(222)
validation_set<- sample(c(1:nrow(datasets::iris)),25)

# Build and train  Network
nn.fit<- dnn(Sepal.Length~., data = datasets::iris[-validation_set,],validation = 0.1)

# show zoomable plot of training and validation losses
analyze_training(nn.fit)

# Use model on validation set
predictions <- predict(nn.fit, iris[validation_set,])

# Scatterplot
plot(iris[validation_set,]$Sepal.Length,predictions)
}
  
  
  
summary(nn.fit)
```

```{r}
dat <- readRDS("../../BEAST_General_Procedures/Project_Frieda/StaticPredictors/out/rds/AllPredictors.rds")

dat0 <- dat %>%

  # Subset to highest resolution (smallest grid size) & first sampling period
  filter(cell_grouping == 1 & exclude == 0 & tp == 1) %>%

  # Initial selection of variables for modeling:
  select(
    # Response / species ID (remove verbatim_name before modelling)
    verbatim_name, Jaccard, log_R2_1, Telfer_1_2,
    # Atlas specifics: [4:8]
    dataset, mean_area, Total_area_samp, Total_Ncells_samp, mean_cell_length,
    # Diversity metrics [9:11]
    GammaSR, AlphaSR_sp, BetaSR_sp,
    # Occupancy [12:15]
    AOO, rel_occ_Ncells, D_AOO_a, mean_prob_cooccur,
    # BirdLife data [16:19]
    sd_PC1, sd_PC2, GlobRangeSize_m2, IUCN,
    # Spatial autocorrelation [20:21]
    moran, x_intercept,
    # AVONET [22:30]
    Mass, Habitat, Habitat.Density, Migration, Trophic.Level, Trophic.Niche, Primary.Lifestyle, FP, Hand.Wing.Index,
    # Species range centroid [31:32]
    sp_centr_lon, sp_centr_lat,
    # Geometry1: [33:36]
    lengthMinRect, widthMinRect, elonMinRect, bearingMinRect,
    # Geometry2: [37:40]
    circ, bearing, Southernness, Westernness,
    # Geometry3: [41:47]
    rel_maxDist, rel_ewDist, rel_nsDist, rel_elonRatio, rel_relCirc, rel_circNorm, rel_lin,
    # Geometry4: [48:51]
    Dist_centroid_to_COG, maxDist_toBorder_border, maxDist_toBorder_centr, minDist_toBorder_centr,
    # Geometry 5: [52:59]
    atlas_lengthMinRect, atlas_widthMinRect, atlas_elonMinRect, atlas_circ,
    atlas_bearingMinRect, atlas_bearing, AtlasCOG_long, AtlasCOG_lat
  ) %>%


  # Fixing some NAs:
  mutate(
    D_AOO_a =
      case_when(is.na(D_AOO_a) & rel_occ_Ncells > 0.97 ~ 2, TRUE ~ D_AOO_a),
      
    mean_prob_cooccur =
      case_when(is.na(mean_prob_cooccur) & rel_occ_Ncells < 0.05 ~ 0, TRUE ~ mean_prob_cooccur)
  ) %>%


  # Delete species with NA in Spatial Autocorrelationn (i.e., those species occupying 100% of area)
  filter(!is.na(moran)) %>%


  # Simplify data and remove replicated rows
  distinct(verbatim_name, dataset, .keep_all = TRUE) %>%


  # Transform all characters to factors for modeling
  mutate_if(is.character, as.factor)


str(dat0)

model_df_turnover <- dat0 %>% select(-verbatim_name, -log_R2_1, -Telfer_1_2) %>% na.omit()
model_df_AOOchange <- dat0 %>% select(-verbatim_name, -Jaccard, -Telfer_1_2) %>% na.omit()


```

```{r}
set.seed(222)
validation_set<- sample(c(1:nrow(model_df_turnover)), size = nrow(model_df_turnover)/5)

# Build and train  Network
nn.fit_turnover <- dnn(Jaccard ~ ., 
                       data = model_df_turnover[-validation_set,],
                       validation = 0.1,
                       hidden = c(50L, 50L, 50L),
                       activation = "relu",
                       loss = "mse",
                       optimizer = "adam",
                       lr = 0.0000000001,
                       epochs = 600000L,
                       lr_scheduler = config_lr_scheduler("reduce_on_plateau", patience = 5, factor = 0.5),
                       plot = TRUE,
                       verbose = TRUE,
                       bootstrap = 1000)


# show zoomable plot of training and validation losses
analyze_training(nn.fit_turnover)

# Use model on validation set
predictions <- predict(nn.fit_turnover, model_df_turnover[validation_set,])

# Scatterplot
plot(model_df_turnover[validation_set,]$Jaccard,predictions)

summary(nn.fit_turnover)

plot(nn.fit_turnover)

```

```{r}
# Build and train  Network
nn.fit_AOOchange <- dnn(log_R2_1 ~ ., 
                       data = model_df_AOOchange[-validation_set,],
                       validation = 0.1,
                       hidden = c(50L, 50L),
                       loss = "mse",
                       optimizer = "rmsprop",
                       lr = 0.000000000001,
                       epochs = 60000L,
                       lr_scheduler = config_lr_scheduler("reduce_on_plateau", patience = 5, factor = 0.5),
                       plot = TRUE,
                       verbose = TRUE,
                       bootstrap = 100)


# show zoomable plot of training and validation losses
analyze_training(nn.fit_AOOchange)

# Use model on validation set
predictions2 <- predict(nn.fit_AOOchange, model_df_AOOchange[validation_set,])

# Scatterplot
plot(model_df_AOOchange[validation_set,]$log_R2_1,predictions2)

summary(nn.fit_AOOchange)

plot(nn.fit_AOOchange)
```
