---
title: "MachineLearning - Script 4 - FinalModels"
author: 
  - name: "MSc. Friederike Johanna Rosa WÃ¶lke"
    orcid: "0000-0001-9034-4883"
    url: "https://friedarosa.github.io"
    email: "wolke@fzp.czu.cz"
    corresponding: true
date: "2023-05-29"
format: 
  html:
    toc: true
    code-fold: true
    code-overflow: wrap
    bibliography: references.bib
keep-tex: true
---

::: panel-tabset
## Source custom functions

```{r}
#| label: load-packages
#| message: FALSE
#| warning: FALSE
rm(list = ls())
source("../src/functions.R")

```

## MachineLearning packages

```{r}
#| label: load-ML-packages
#| message: FALSE
#| error: FALSE

pckgs <- c("dplyr", "ggplot2", "reshape2", 
           "ggcorrplot", 
           "caret",  "recipes",   "caretEnsemble", 
           "randomForest", "ranger", "gbm", "xgboost", 
           "vegan", "pdp", 
           "gridExtra", "kableExtra")

install_and_load(pckgs)
```

## Load RData to reduce computing time

```{r}
#| label: load-RData
#| message: FALSE
#| error: FALSE

# Load workspace to save computing time:
## it has: varPart from ranger models
## recursive feature selection results

# load("data/varPart_rfe.RData")
# load("data/models.RData")
load("../data/RData/01_Data_prep.RData")
```
:::

##### Insights:

1.  Random Forest with Ranger Keeping in mind that splitrule = "extratrees" ignores the mtry argument (and rather performs random selection of variables). This should prevent overfitting and achieves a similar performance to mtry = intermediate number and splitrule = "variance".

2.  Extreme Gradient Boosted Trees

3.  Boosted Regression Trees

```{r}
#| label: final-models-ranger

trainControl <- trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 3,
    savePredictions = "final",
    returnResamp = "final",
    verboseIter = FALSE,
    index = indices)

# Train ranger model
ranger_grid <- expand.grid(
    splitrule = "variance",
    mtry = 29,
    min.node.size = 5)

# tictoc::tic("ranger")
# set.seed(42)
# rangerModel <- train(
#     Jaccard ~ .,
#     data = dat_train,
#     method = "ranger",
#     trControl = trainControl,
#     importance = "permutation",
#     scale.permutation.importance = TRUE,
#     num.trees = 5000,
#     respect.unordered.factors = TRUE,
#     oob.error = TRUE,
#     tuneGrid = ranger_grid)
# tictoc::toc()
# saveRDS(rangerModel, "./data/rangerModel_final.rds")

rangerModel <- readRDS("./data/rangerModel_final.rds")

# Performance checks ======
## with external data (from initial split)
test_performance_rf <- data.frame(
    prediction = predict(rangerModel, newdata = dat_test),
    observed = dat_test$Jaccard) %>%
    mutate(test_error = observed-prediction)

round(mean(test_performance_rf$test_error), 4) 
# mean test error = 0.0092 (mtry = 29) // 0.0099 (mtry = 57)
postResample(test_performance_rf$observed, 
test_performance_rf$prediction)


p_pred_rangerModel <- ggplot(aes(observed, prediction), 
                             data = test_performance_rf)+
  geom_point()+
  geom_smooth(method = "lm")+
  ylim(0,1)+
  xlim(0,1)+
  theme_bw()

p_pred_rangerModel

```

```{r}
#| label: final-models-xgb
## custom tuning for xgb:
xgb_grid <- expand.grid(
  nrounds = 150,
  eta = 0.3,
  max_depth = 2,
  gamma = 0,
  colsample_bytree = 0.6,
  min_child_weight = 1,
  subsample = 1)

# tictoc::tic("xgb")
# set.seed(42)
# xgbModel <- train(
#     Jaccard ~ .,
#     data = dat_train,
#     method = "xgbTree",
#     trControl = trainControl,
#     tuneGrid = xgb_grid)
# tictoc::toc()
# saveRDS(xgbModel, "./data/xgbModel_final.rds")

xgbModel <- readRDS("./data/xgbModel_final.rds")

## Check test performance with external data (from initial split)
test_performance_xgb <- data.frame(
    prediction = predict(xgbModel, newdata = dat_test),
    observed = dat_test$Jaccard) %>%
    mutate(test_error = observed-prediction)

round(mean(test_performance_xgb$test_error), 4) 
# mean test error = 
postResample(test_performance_xgb$observed, 
test_performance_xgb$prediction)

p_pred_xgbModel <- ggplot(aes(observed, prediction), data = test_performance_xgb)+
    geom_point()+
    geom_smooth(method = "lm")+
    ylim(0,1)+
    xlim(0,1)+
    theme_bw()
p_pred_xgbModel

```

```{r}
#| label: final-models-gbm
# Train gbm model
gbm_grid <-  expand.grid(interaction.depth = 15, 
                        n.trees = 350, 
                        shrinkage = 0.1,
                        n.minobsinnode = 10)
# tictoc::tic("gbm")
# set.seed(42)
# gbmModel <- train(
#     Jaccard ~ .,
#     data = dat_train,
#     method = "gbm",
#     trControl = trainControl,
#     tuneGrid = gbm_grid,
#     verbose = FALSE)
# tictoc::toc()
# saveRDS(gbmModel, "./data/gbmModel_final.rds")

gbmModel <- readRDS("./data/gbmModel_final.rds")

## Check test performance with external data (from initial split)
test_performance_gbm <- data.frame(
    prediction = predict(gbmModel, newdata = dat_test),
    observed = dat_test$Jaccard) %>%
    mutate(test_error = observed-prediction)

round(mean(test_performance_gbm$test_error), 4) 
# mean test error = 
postResample(test_performance_gbm$observed, test_performance_gbm$prediction)

p_pred_gbmModel <- ggplot(aes(observed, prediction), data = test_performance_gbm)+
    geom_point()+
    geom_smooth(method = "lm")+
    ylim(0,1)+
    xlim(0,1)+
    theme_bw()
p_pred_gbmModel

```

### Compare models

```{r}
#| label: final-models-comparison
# Prediction error for test data ============
test_error_all <- data.frame(
    observed = dat_test$Jaccard,
    pred_ranger = predict(rangerModel, newdata=dat_test),
    pred_xgb = predict(xgbModel, newdata=dat_test),
    pred_gbm = predict(gbmModel, newdata=dat_test)) %>%
    mutate(
        test_error_ranger = observed-pred_ranger,
        test_error_xgb = observed-pred_xgb,
        test_error_gbm = observed-pred_gbm)

round(mean(test_error_all$test_error_ranger),4)
round(mean(test_error_all$test_error_xgb),4)
round(mean(test_error_all$test_error_gbm),4)
print(test_error_all)

# Variable importance ============
imp_rf <- varImp(rangerModel, type=1)$importance %>% 
    rename("Imp_ranger" = "Overall")
imp_xgb <- varImp(xgbModel, type=1)$importance %>% 
    rename("Imp_xgb" = "Overall")
imp_gbm <- varImp(gbmModel, type=1)$importance %>% 
    rename("Imp_gbm" = "Overall")

imp_temp <- merge(imp_rf, imp_xgb, by = "row.names", all = TRUE)
imp_all <- merge(imp_temp, imp_gbm, by.x = "Row.names", by.y = "row.names", all = TRUE) %>% mutate_if(is.numeric, round, 2) %>%
arrange(desc(Imp_ranger))

# Compare models using resamples ============
resamples <- resamples(list(
    ranger = rangerModel,
    xgbTree = xgbModel,
    gbm = gbmModel))

summary(resamples)
xyplot(resamples)

# Plot comparison
bwplot(resamples)
```

```{r}
#| eval: FALSE
#| label: save-image-load-image
save.image("./data/models.RData")
load("./data/models.RData")
```

### Partial Dependence Plots

```{r}
#| label: partial-dependence-plots
#| fig.width: 18
#| fig.height: 40

## Partial dependence plots
# Get all partial dependencies ==================
# pp_list_ranger <- replicate(39, list())
# for (var in seq_along(1:length(names(dat_train %>% select(-Jaccard))))){
#     pred_var <- names(dat_train %>% select(-Jaccard))[var]
#     pp_list_ranger[[var]] <- pdp::partial(
#         rangerModel, 
#         pred.var = pred_var, 
#         plot = FALSE)
# }
# 
# 
# 
# pp_list_xgb <- replicate(39, list())
# for (var in seq_along(1:length(names(dat_train %>% select(-Jaccard))))){
#     pred_var <- names(dat_train %>% select(-Jaccard))[var]
#     pp_list_xgb[[var]] <- partial(
#         xgbModel, 
#         pred.var = pred_var, 
#         plot = FALSE)
# }
# 
# 
# 
# 
# pp_list_gbm <- replicate(39, list())
# for (var in seq_along(1:length(names(dat_train %>% select(-Jaccard))))){
#     pred_var <- names(dat_train %>% select(-Jaccard))[var]
#     pp_list_gbm[[var]] <- partial(
#         gbmModel, 
#         pred.var = pred_var, 
#         plot = FALSE)
# }
# 
# 
# pp_list <- list(pp_list_ranger, pp_list_xgb, pp_list_gbm)
#
# saveRDS(pp_list, "data/pp_list.rds")

pp_list <- readRDS("./data/pp_list.rds")
pp_list_ranger <- pp_list[[1]]
pp_list_xgb <- pp_list[[2]]
pp_list_gbm <- pp_list[[3]]


## Evaluate model =====

# Plotting

# Define the predictor names
predictors <- names(dat_train %>% select(-Jaccard))

# Initialize an empty list to store the plots
plots <- list()

# Function to determine if a column is categorical
is_categorical <- function(column) {
  is.factor(column) || is.character(column)
}

# Loop through the indices and create plots
for (i in seq_along(1:length(predictors))) {
  predictor <- names(pp_list_ranger[[i]])[1]
  
  if (is_categorical(dat_train[[predictor]])) {
    # Create boxplot for categorical predictors
    plots[[i]] <- ggplot() +
      geom_boxplot(data = pp_list_ranger[[i]], aes(x = .data[[predictor]], y = yhat)) +
      geom_boxplot(data = pp_list_xgb[[i]],aes(x = .data[[predictor]], y = yhat), linetype = "dashed") +
      geom_boxplot(data = pp_list_gbm[[i]], aes(x = .data[[predictor]], y = yhat), linetype = "dotted") +
      labs(x = paste(predictor), y = "Partial Dependence", title = "Partial Dependence Boxplots") +
      theme_bw() +
      ylim(0, 1)
  } else {
    # Create line plot for continuous predictors
    plots[[i]] <- ggplot() +
      geom_line(data = pp_list_ranger[[i]], aes(x = .data[[predictor]], y = yhat)) +
      geom_line(data = pp_list_xgb[[i]], aes(x = .data[[predictor]], y = yhat), linetype = "dashed") +
      geom_line(data = pp_list_gbm[[i]], aes(x = .data[[predictor]], y = yhat), linetype = "dotted") +
      labs(x = paste(predictor), y = "Partial Dependence", title = "Partial Dependence Plots") +
      theme_bw() +
      ylim(0, 1)
  }
}

# Arrange the plots in a grid
gridExtra::grid.arrange(grobs = plots, ncol = 6)

```

### Ensemble model

Now we will compare randomForest to boosed regression trees or extreme gradient boosting.

```{r}
#| label: ensemble-model


set.seed(42)
trained_control <- trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 3,
    savePredictions = "final",
    returnResamp = "final",
    verboseIter = TRUE,
    index = indices)

modelsList <- caretList(
    Jaccard ~ .,
    data = dat_train,
    trControl = trained_control,
    methodList = list("gbm", "xgbTree"),
    tuneList = list(
      ranger = caretModelSpec(
        method = "ranger", 
        importance = "permutation",
        scale.permutation.importance = TRUE,
        num.trees = 5000,
        respect.unordered.factors = TRUE,
        oob.error = TRUE, 
        tuneGrid = ranger_grid)))

p <- as.data.frame(predict(modelsList, newdata = dat_test)) %>% 
  cbind(dat_test$Jaccard) %>%
  mutate(
    error_ranger = dat_test$Jaccard-ranger,
    error_gbm = dat_test$Jaccard-gbm,
    error_xgb = dat_test$Jaccard-xgbTree) 
p %>%
  summarise(mean_ranger = mean(error_ranger),
            mean_gbm = mean(error_gbm),
            mean_xgb = mean(error_xgb)) %>% kableExtra::kable() # ranger performs best

xyplot(resamples(modelsList))

# Create the ensemble model
ensembleModel <- caretEnsemble(
    modelsList,
    metric = "Rsquared",
    trControl = trained_control)
summary(ensembleModel)


# The ensemble model is not better than the ranger model alone. In fact, it's a bit worse. We will discard the ensembleModel approach therefore.

imp_ranger <- varImp(modelsList[[1]])$importance %>% as.data.frame() %>% rename("imp_ranger" = "Overall")
imp_gbm <- varImp(modelsList[[2]])$importance %>% as.data.frame()%>% rename("imp_gbm" = "Overall")
imp_xgb <- varImp(modelsList[[3]])$importance %>% as.data.frame()%>% rename("imp_xgb" = "Overall")


imp_ranger$var <- row.names(imp_ranger)
imp_gbm$var <- row.names(imp_gbm)
imp_xgb$var <- row.names(imp_xgb)


imp_merged <- merge(imp_ranger, imp_gbm)
imp_merged_all <- merge(imp_merged, imp_xgb) %>% arrange(desc(imp_ranger))

imp_merged_all %>% kableExtra::kable()


```

### Train Neural Network

We will train 10 sets of neural networks (one for each resample of the data splitting)

```{r}
#| label: train-neural-network
#| include: TRUE
#| eval: FALSE


for (resamp in seq_along(indices)) {
    train_df <- dat_v2[indices[[resamp]], ] # 826 rows
    test_df <- dat_v2[-indices[[resamp]], ] # 204 rows

    nn_fit <- dnn(Jaccard ~ .,
        data = train_df %>% select(Jaccard, AOO, D_AOO_a, IUCN),
        validation = 0.2,
        hidden = c(50L, 50L, 50L, 50L),
        activation = "relu",
        loss = "mse",
        lr = 0.0001,
        epochs = 6000L,
        lr_scheduler = config_lr_scheduler("reduce_on_plateau", patience = 10, factor = 0.5),
        plot = TRUE,
        tuning = config_optimizer("adam"),
        verbose = TRUE,
        bootstrap = 1000
    )


    analyze_training(nn_fit)

    predictions <- predict(nn_fit, test_df)

    plot(test_df$Jaccard, predictions)

    summary(nn_fit)
}


```

## /
