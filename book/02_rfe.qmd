---
title: "Script 2 - Recursive Feature Selection"
author: 
  - name: "MSc. Friederike Johanna Rosa Wölke"
    orcid: "0000-0001-9034-4883"
    url: "https://friedarosa.github.io"
    email: "wolke@fzp.czu.cz"
    corresponding: true
date: "2023-05-29"
---

# Recursive feature elimination

I will use recursive feature elimination to reduce the dimensionality of the data by removing variables that do not lead to an increase of model performance when included.
I will apply this method, because most of my predictors were calculated from the same data and are thus not independent.
Although checking for high correlations in one of the previous steps, any correlations between predictor variables may confuse the model during variation partitioning, as correlations make it impossible to discern which variable explains how much of the variation.
This also reduces the probability of overfitting the model to the data as redundant features with correlated noise signals are removed.

The method being used relies on the `randomForest` package to recursively eliminate one predictor after another from the model, calculate the variable importance, rank these, average the importance across resamples and comparing the fit across models with different subsets of the set of predictors.
The workflow is set in the `caret` helper function `rfFuncs()`.

::: panel-tabset
## Source custom functions

```{r}
#| label: load-packages
#| message: FALSE
#| warning: FALSE
rm(list = ls())

source("../src/functions.R")

```

## MachineLearning packages

```{r}
#| label: load-ML-packages
#| message: FALSE
#| error: FALSE

pckgs <- c("dplyr", "ggplot2", "reshape2", 
           "ggcorrplot", 
           "caret",  "recipes",   "caretEnsemble", 
           "randomForest", 
           "gridExtra", "kableExtra", "tidyr")

install_and_load(pckgs)
```

## Load RData to reduce computing time

```{r}
#| label: load-RData
#| message: FALSE
#| error: FALSE

# Load workspace to save computing time:
## it has: varPart from ranger models
## recursive feature selection results

# load("../data/RData/01_Data_prep.RData")
load("../data/RData/02_rfe_5000.RData")
```
:::

### Predictor importance / Recursive Feature Selection

We will set up a loop that runs through the four response variables that I am investigating.
The models from which the variable importance is calculated are run for 5000 trees each across 10 resamples.
Again I will be using 10-fold repeated cross-validation with 3 repeats to evaluate the performance of the models.

```{r}
#| eval: false
#| label: rfe-loop


index_list <- list(indices_J1, indices_J2, indices_LR1, indices_LR2)
dat_train_list <- list(dat_train_J1, dat_train_J2, dat_train_LR1, dat_train_LR2)

saved_profiles <- replicate(4, list())
# names(saved_profiles) <- c("J1", "J2", "LR1", "LR2")
save_imp <- replicate(4, list())
# names(save_imp) <- c("J1", "J2", "LR1", "LR2")

response_list <- c("Jaccard", "Jaccard", "log_R2_1", "log_R2_1")

for(j in seq_along(1:4)){
  ## Loop through differet datasets/Analyses
  indices <- index_list[[j]]
  dat_train <- dat_train_list[[j]]
  response <- response_list[[j]] 
  saved_profiles[[j]] <- replicate(4, list())
  save_imp[[j]] <- replicate(4, list())
  
  ## Recursive feature selection:
  set.seed(42)
  ctrl <- rfeControl(
    functions = rfFuncs,
    method = "repeatedcv",
    number = 10,
    repeats = 3,
    returnResamp = "all", # we need all resamples
    verbose = FALSE,
    index = indices,
    saveDetails = TRUE)

  ctrl$functions$rank <- rank #adjust rank function

  ## Set variables for recursive feature elimination
  subsets <- c(1:50) # number of predictors in each run
  x <- dat_train %>% select(!all_of(response))
  y <- dat_train %>% pull(response)
  
  ## First run:
  set.seed(42)
  rfProfile <- rfe(x, y, ntree = 5000, sizes = subsets, rfeControl = ctrl)
  rfProfile
    
  # Most important predictors:
  imp <- as.data.frame(rfProfile$fit$importance) %>%
                   round(3) %>%
                   select(`%IncMSE`) %>% 
                   mutate(var = row.names(.)) %>%
                   arrange(desc(`%IncMSE`))    
    
  saved_profiles[[j]] <- rfProfile
  save_imp[[j]] <- imp
}

saveRDS(saved_profiles, file = "../data/02_rfe_saved_profiles_5000.rds")
save.image(file = "../data/RData/02_rfe_5000.RData")
```

```{r}
#| label: rfe-results-eval
#| fig.height: 4
#| fig.width: 4
#| eval: true
#| warning: false

saved_profiles[[1]]$bestSubset
saved_profiles[[2]]$bestSubset
saved_profiles[[3]]$bestSubset
saved_profiles[[4]]$bestSubset



results <- replicate(4, list())
    for (i in seq_along(1:4)){
        resamp_res <- saved_profiles[[i]]
        res <- slice_min(resamp_res$results, RMSE)
        results[[i]] <- res
    }

names(results) <- c("J1", "J2", "LR1", "LR2")
rfe_res <- do.call(rbind, results)
rfe_res$dd <- rownames(rfe_res)


# Bar plot: Nr. Vars selected for each analysis 
ggplot(data = rfe_res, aes(x = dd, y = Variables)) +
    geom_col(fill = "lightgrey") +
    geom_point(data = rfe_res %>% group_by(dd) %>% summarize(mean_Variables = mean(Variables)), 
    aes(x = dd, y = mean_Variables), color = "red") +
    theme_classic()+
    labs(title = "Number of variables selected per analysis", y = "Number of variables selected", x = "Analysis")


# Add mean importance across resamples to results
saved_profiles[[1]]$variables <- saved_profiles[[1]]$variables %>% filter(Variables == 39) %>%
  group_by(var) %>%
  mutate(Overall_mean_resamp = mean(Overall)) %>%
  mutate(hypo = case_when(var %in% H1_vars ~ "H1",
                          var %in% H2_vars ~ "H2",
                          var %in% H3_vars ~ "H3",
                          var %in% H4_vars ~ "H4"))

saved_profiles[[2]]$variables <- saved_profiles[[2]]$variables %>% filter(Variables == 38) %>%
  group_by(var) %>%
  mutate(Overall_mean_resamp = mean(Overall))%>%
  mutate(hypo = case_when(var %in% H1_vars ~ "H1",
                          var %in% H2_vars ~ "H2",
                          var %in% H3_vars ~ "H3",
                          var %in% H4_vars ~ "H4"))

saved_profiles[[3]]$variables <- saved_profiles[[3]]$variables %>% filter(Variables == 39) %>%
  group_by(var) %>%
  mutate(Overall_mean_resamp = mean(Overall))%>%
  mutate(hypo = case_when(var %in% H1_vars ~ "H1",
                          var %in% H2_vars ~ "H2",
                          var %in% H3_vars ~ "H3",
                          var %in% H4_vars ~ "H4"))

saved_profiles[[4]]$variables <- saved_profiles[[4]]$variables %>% filter(Variables == 38) %>%
  group_by(var) %>%
  mutate(Overall_mean_resamp = mean(Overall))%>%
  mutate(hypo = case_when(var %in% H1_vars ~ "H1",
                          var %in% H2_vars ~ "H2",
                          var %in% H3_vars ~ "H3",
                          var %in% H4_vars ~ "H4"))
```

::: panel-tabset
## Jaccard

The following plots show, that the data that can be used to predict Jaccard can be reduced enormously without losing predictive performance.

For *`Jaccard1`* the

-   reduced model yields: RMSE = 0.1116 and R² = 0.8450,

-   while the full model yields: RMSE = 0.1118 and R² = 0.8455.

showing even a slightly reduced RMSE compared to the full model.

For Jaccard 2 the

-   reduced model yields: RMSE = 0.1248 and R² = 0.8077,

-   while the full model yields: RMSE = 0.1273 and R² = 0.8022.

```{r}
#| label: rfe-results-boxplot-j
#| fig.height: 8
#| fig.width: 10
#| eval: true
#| warning: false

# On best models (best hyper parameters)
saved_profiles[[1]]$fit 
saved_profiles[[1]]$fit %>% varImp()
plot(saved_profiles[[1]])


saved_profiles[[2]]$fit
saved_profiles[[2]]$fit %>% varImp()
plot(saved_profiles[[2]])

## Plot the importances

grid.arrange(ncol=2,
saved_profiles[[1]]$variables %>% filter(Variables == 39) %>%
  group_by(var) %>%
  ggplot()+
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = (39.5-saved_profiles[[1]]$bestSubset)), fill = "lightgray", alpha = 0.9) +
  geom_boxplot(aes(y = reorder(var, Overall), x = Overall, fill = hypo ), show.legend = FALSE)+
  geom_point(aes(x = Overall_mean_resamp, y = var), col = "red", alpha = 0.4)+
  theme_classic()+
  xlim(0,100)+
  scale_fill_manual(values = c("#e66101", "#fdb863", "#b2abd2", "#5e3c99")) +
  labs(title = "Variables by Importance: Jaccard tp = 1", x = "Importance", y = "Variable"),


saved_profiles[[2]]$variables %>% filter(Variables == 38) %>%
  group_by(var) %>%
  ggplot()+
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = (39.5-saved_profiles[[2]]$bestSubset)), fill = "lightgray", alpha = 0.9) +
  geom_boxplot(aes(y = reorder(var, Overall), x = Overall, fill = hypo ))+
  geom_point(aes(x = Overall_mean_resamp, y = var), col = "red", alpha = 0.4)+
  theme_classic()+
  xlim(0,100)+
  scale_fill_manual(values = c("#e66101", "#fdb863", "#b2abd2", "#5e3c99")) +
  labs(title = "Variables by Importance: Jaccard tp = 2", x = "Importance", y = "Variable")
)
```

## Log Ratio

For `log ratio of AOO,` we can see that we need more predictors than for `Jaccard` to predict it from the data.
As expected before, the model performance is generally low (both R² = 0.147) and the models try to include more information to discern the relationship between predictors and the response that does not capture a big signal from temporal change.

```{r}
#| label: rfe-results-boxplot-lr
#| fig.height: 8
#| fig.width: 10
#| eval: true
#| warning: false

# On best models (best hyper parameters)
saved_profiles[[3]]$fit 
saved_profiles[[3]]$fit %>% varImp()
plot(saved_profiles[[3]])


saved_profiles[[4]]$fit
saved_profiles[[4]]$fit %>% varImp()
plot(saved_profiles[[4]])


grid.arrange(ncol=2,
saved_profiles[[3]]$variables %>% filter(Variables == 39) %>%
  group_by(var) %>%
  ggplot()+
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = (39.5-saved_profiles[[3]]$bestSubset)), fill = "lightgray", alpha = 0.9) +
  geom_boxplot(aes(y = reorder(var, Overall), x = Overall, fill = hypo ), show.legend = FALSE)+
  geom_point(aes(x = Overall_mean_resamp, y = var), col = "red", alpha = 0.4)+
  theme_classic()+
  xlim(0,100)+
  scale_fill_manual(values = c("#e66101", "#fdb863", "#b2abd2", "#5e3c99")) +
  labs(title = "Variables by Importance: log ratio tp = 1", x = "Importance", y = "Variable"),

saved_profiles[[4]]$variables %>% filter(Variables == 38) %>%
  group_by(var) %>%
  ggplot()+
  geom_rect(aes(xmin = -Inf, xmax = Inf, ymin = -Inf, ymax = (39.5-saved_profiles[[4]]$bestSubset)), fill = "lightgray", alpha = 0.9) +
  geom_boxplot(aes(y = reorder(var, Overall), x = Overall, fill = hypo ))+
  geom_point(aes(x = Overall_mean_resamp, y = var), col = "red", alpha = 0.4)+
  theme_classic()+
  xlim(0,100)+
  scale_fill_manual(values = c("#e66101", "#fdb863", "#b2abd2", "#5e3c99")) +
  labs(title = "Variables by Importance: log ratio tp = 2", x = "Importance", y = "Variable")
)
```
:::

```{r}
Imp_list <- replicate(4, list())
Imp_list[[1]] <- saved_profiles[[1]]$variables %>% 
  select(Overall_mean_resamp, var) %>%
  rename("imp" = "Overall_mean_resamp") %>%
  mutate(model = "J1")
Imp_list[[2]] <- saved_profiles[[2]]$variables %>%
  select(Overall_mean_resamp, var) %>%
  rename("imp" = "Overall_mean_resamp")%>%
  mutate(model = "J2")

Imp_list[[3]] <- saved_profiles[[3]]$variables %>%
  select(Overall_mean_resamp, var) %>%
  rename("imp" = "Overall_mean_resamp")%>%
  mutate(model = "LR1")

Imp_list[[4]] <- saved_profiles[[4]]$variables %>%
  select(Overall_mean_resamp, var) %>%
  rename("imp" = "Overall_mean_resamp")%>%
  mutate(model = "LR2")

# Included vars:
J1_vars <- saved_profiles[[1]]$fit$importance
J2_vars <- saved_profiles[[2]]$fit$importance
LR1_vars <- saved_profiles[[3]]$fit$importance
LR2_vars <- saved_profiles[[4]]$fit$importance

Imp_df <- do.call(rbind, Imp_list)
wide <- Imp_df %>%
  tidyr::pivot_wider(names_from = c(model), 
                     values_from = imp, names_sep = "_", 
                     values_fn = mean) %>% 
  arrange(desc(J1)) %>% 
  group_by(var) %>%  
  mutate(hypo = case_when(var %in% H1_vars ~ "H1",
                          var %in% H2_vars ~ "H2",
                          var %in% H3_vars ~ "H3",
                          var %in% H4_vars ~ "H4")) %>%
  mutate(Include_J1 = case_when(var %in% c(row.names(J1_vars)) ~ 1, 
         .default = 0), 
         Include_J2 = case_when(var %in% c(row.names(J2_vars)) ~ 1, 
         .default = 0),
         Include_LR1 = case_when(var %in% c(row.names(LR1_vars)) ~ 1, 
         .default = 0),
         Include_LR2 = case_when(var %in% c(row.names(LR2_vars)) ~ 1, 
         .default = 0))

wide %>% write.csv("../data/csv/02_all_var_imp_5000.csv")
wide %>% kableExtra::kable()
```


# Compare reduced and full ranger models
Since the rfe function works with the randomForest package, we will check if we get similarly better results with ranger and the reduced model.
::: panel-tabset
## Jaccard 1
```{r}
#| label: compare-ranger-results-J1

J1_vars <- wide %>% filter(Include_J1 == 1) %>% pull(var)

response <- "Jaccard"

indices <- indices_J1

dat_train <- dat_train_J1


# Define training control ==========================================================
  trainControl <- trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 3,
    savePredictions = "final",
    returnResamp = "all",
    verboseIter = FALSE,
    index = indices)

  ## Train ranger model ==========================================================
  set.seed(42)
  tictoc::tic("ranger")
  J1_full <- train(
    as.formula(paste(response, "~ .")),
    data = dat_train,
    method = "ranger",
    trControl = trainControl,
    importance = "permutation",
    scale.permutation.importance = TRUE,
    num.trees = 5000,
    respect.unordered.factors = TRUE,
    oob.error = TRUE,
    tuneLength = 20)
  
  # saveRDS(rangerModel_t, paste0("../data/rds/rangerModel_", response, j, "all.rds"))
  tictoc::toc()
  
  
  
    set.seed(42)
  tictoc::tic("ranger")
  J1_reduced <- train(
    as.formula(paste(response, "~ .")),
    data = dat_train %>% select(response, all_of(J1_vars)),
    method = "ranger",
    trControl = trainControl,
    importance = "permutation",
    scale.permutation.importance = TRUE,
    num.trees = 5000,
    respect.unordered.factors = TRUE,
    oob.error = TRUE,
    tuneLength = 20)
  
  # saveRDS(rangerModel_t, paste0("../data/rds/rangerModel_", response, j, "all.rds"))
  tictoc::toc()
  J1_full$finalModel
  J1_full$results

  J1_reduced$finalModel
  J1_reduced$results

```

## Jaccard 2
```{r}
#| label: compare-ranger-results-J2

J2_vars <- wide %>% filter(Include_J2 == 1) %>% pull(var)

response <- "Jaccard"

indices <- indices_J2

dat_train <- dat_train_J2


# Define training control ==========================================================
  trainControl <- trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 3,
    savePredictions = "final",
    returnResamp = "all",
    verboseIter = FALSE,
    index = indices)

  ## Train ranger model ==========================================================
  set.seed(42)
  tictoc::tic("ranger")
  J2_full <- train(
    as.formula(paste(response, "~ .")),
    data = dat_train,
    method = "ranger",
    trControl = trainControl,
    importance = "permutation",
    scale.permutation.importance = TRUE,
    num.trees = 5000,
    respect.unordered.factors = TRUE,
    oob.error = TRUE,
    tuneLength = 20)
  
  # saveRDS(rangerModel_t, paste0("../data/rds/rangerModel_", response, j, "all.rds"))
  tictoc::toc()
  
  
  
    set.seed(42)
  tictoc::tic("ranger")
  J2_reduced <- train(
    as.formula(paste(response, "~ .")),
    data = dat_train %>% select(response, all_of(J2_vars)),
    method = "ranger",
    trControl = trainControl,
    importance = "permutation",
    scale.permutation.importance = TRUE,
    num.trees = 5000,
    respect.unordered.factors = TRUE,
    oob.error = TRUE,
    tuneLength = 20)
  
  # saveRDS(rangerModel_t, paste0("../data/rds/rangerModel_", response, j, "all.rds"))
  tictoc::toc()
  J2_full$finalModel
  J2_full$results

  J2_reduced$finalModel
  J2_reduced$results

```

## Log Ratio 1
```{r}
#| label: compare-ranger-results-LR1

LR1_vars <- wide %>% filter(Include_LR1 == 1) %>% pull(var)

response <- "log_R2_1"

indices <- indices_LR1

dat_train <- dat_train_LR1


# Define training control ==========================================================
  trainControl <- trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 3,
    savePredictions = "final",
    returnResamp = "all",
    verboseIter = FALSE,
    index = indices)

  ## Train ranger model ==========================================================
  set.seed(42)
  tictoc::tic("ranger")
  LR1_full <- train(
    as.formula(paste(response, "~ .")),
    data = dat_train,
    method = "ranger",
    trControl = trainControl,
    importance = "permutation",
    scale.permutation.importance = TRUE,
    num.trees = 5000,
    respect.unordered.factors = TRUE,
    oob.error = TRUE,
    tuneLength = 20)
  
  # saveRDS(rangerModel_t, paste0("../data/rds/rangerModel_", response, j, "all.rds"))
  tictoc::toc()
  
  
  
    set.seed(42)
  tictoc::tic("ranger")
  LR1_reduced <- train(
    as.formula(paste(response, "~ .")),
    data = dat_train %>% select(response, all_of(LR1_vars)),
    method = "ranger",
    trControl = trainControl,
    importance = "permutation",
    scale.permutation.importance = TRUE,
    num.trees = 5000,
    respect.unordered.factors = TRUE,
    oob.error = TRUE,
    tuneLength = 20)
  
  # saveRDS(rangerModel_t, paste0("../data/rds/rangerModel_", response, j, "all.rds"))
  tictoc::toc()
  LR1_full$finalModel
  LR1_full$results
  LR1_reduced$finalModel
  LR1_reduced$results

```


## Log Ratio 2
```{r}
#| label: compare-ranger-results-LR2

LR2_vars <- wide %>% filter(Include_LR2 == 1) %>% pull(var)

response <- "log_R2_1"

indices <- indices_LR2

dat_train <- dat_train_LR2


# Define training control ==========================================================
  trainControl <- trainControl(
    method = "repeatedcv",
    number = 10,
    repeats = 3,
    savePredictions = "final",
    returnResamp = "all",
    verboseIter = FALSE,
    index = indices)

  ## Train ranger model ==========================================================
  set.seed(42)
  tictoc::tic("ranger")
  LR2_full <- train(
    as.formula(paste(response, "~ .")),
    data = dat_train,
    method = "ranger",
    trControl = trainControl,
    importance = "permutation",
    scale.permutation.importance = TRUE,
    num.trees = 5000,
    respect.unordered.factors = TRUE,
    oob.error = TRUE,
    tuneLength = 20)
  
  # saveRDS(rangerModel_t, paste0("../data/rds/rangerModel_", response, j, "all.rds"))
  tictoc::toc()
  
  
  
    set.seed(42)
  tictoc::tic("ranger")
  LR2_reduced <- train(
    as.formula(paste(response, "~ .")),
    data = dat_train %>% select(response, all_of(LR2_vars)),
    method = "ranger",
    trControl = trainControl,
    importance = "permutation",
    scale.permutation.importance = TRUE,
    num.trees = 5000,
    respect.unordered.factors = TRUE,
    oob.error = TRUE,
    tuneLength = 20)
  
  # saveRDS(rangerModel_t, paste0("../data/rds/rangerModel_", response, j, "all.rds"))
  tictoc::toc()
  
  LR2_full$finalModel
  LR2_full$results
  LR2_reduced$finalModel
  LR2_reduced$results


```
:::


```{r}
save.image("../data/RData/rfe_full_vs_reduced.RData")
selected_predictors <- list(J1_vars, J2_vars, LR1_vars, LR2_vars)
saveRDS(selected_predictors, "../data/rds/selected_predictors_list.rds")
```
